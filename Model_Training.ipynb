{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook contains the code used to train, tune and evaluate each potential binary classifier model, followed by further tuning of the Neural Network.**"
      ],
      "metadata": {
        "id": "H41EMew1wVJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# Load the training data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "train_data['label'] = pd.to_numeric(train_data['label'], downcast='integer', errors='coerce')\n",
        "X_train_full = train_data.drop('label', axis=1)\n",
        "y_train_full = train_data['label']\n",
        "\n",
        "# Load the test data (final evaluation)\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv')\n",
        "test_data['label'] = pd.to_numeric(test_data['label'], downcast='integer', errors='coerce')\n",
        "X_test = test_data.drop('label', axis=1)\n",
        "y_test = test_data['label']\n",
        "\n",
        "# Create validation split (20%) from training data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "EBXXzny8hxY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to evaluate models\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    start_time = time.time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    avg_inference_time = (time.time() - start_time) / len(y_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"{model_name} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Average Inference Time: {avg_inference_time:.6f} seconds\\n\")\n",
        "\n",
        "    return {\n",
        "        'model': model_name,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'inference_time': avg_inference_time\n",
        "    }\n",
        "\n",
        "def evaluate_tf_model(model, X_test, y_test, model_name):\n",
        "    start_time = time.time()\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "    avg_inference_time = (time.time() - start_time) / len(y_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{model_name} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Average Inference Time: {avg_inference_time:.6f} seconds\")\n",
        "\n",
        "    return {\n",
        "        'model': model_name,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'inference_time': avg_inference_time\n",
        "    }"
      ],
      "metadata": {
        "id": "k3HZcisDiMrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Logistic Regression\n",
        "print(\"Tuning Logistic Regression...\")\n",
        "log_reg_params = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "best_log_reg = None\n",
        "best_log_reg_score = 0\n",
        "\n",
        "for C in log_reg_params['C']:\n",
        "    model = LogisticRegression(C=C, penalty='l2', solver='liblinear', max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    val_score = model.score(X_val, y_val)\n",
        "\n",
        "    if val_score > best_log_reg_score:\n",
        "        best_log_reg_score = val_score\n",
        "        best_log_reg = model\n",
        "\n",
        "    print(f\"C: {C}, Validation Accuracy: {val_score:.4f}\")\n",
        "\n",
        "log_reg_metrics = evaluate_model(best_log_reg, X_test, y_test, \"Logistic Regression (Tuned)\")\n",
        "joblib.dump(best_log_reg, '/content/drive/MyDrive/Colab Notebooks/logistic_regression_model_tuned.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKQ4aAZ0iWli",
        "outputId": "c62ab387-60db-446d-b8aa-a54de668257d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C: 0.1, Validation Accuracy: 0.7115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C: 1, Validation Accuracy: 0.7110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C: 10, Validation Accuracy: 0.7113\n",
            "Logistic Regression (Tuned) Metrics:\n",
            "Accuracy: 0.7113\n",
            "Precision: 0.7993\n",
            "Recall: 0.3695\n",
            "F1 Score: 0.5053\n",
            "Average Inference Time: 0.000000 seconds\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/logistic_regression_model_tuned.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Gradient Boosting\n",
        "print(\"Tuning Gradient Boosting Machine...\")\n",
        "gbm_params = {\n",
        "    'n_estimators': [25, 50, 75],\n",
        "    'learning_rate': [0.1, 0.2, 0.3],\n",
        "    'max_depth': [2, 3, 4]\n",
        "}\n",
        "\n",
        "best_gbm = None\n",
        "best_gbm_score = 0\n",
        "\n",
        "for n_est in gbm_params['n_estimators']:\n",
        "    for lr in gbm_params['learning_rate']:\n",
        "        for depth in gbm_params['max_depth']:\n",
        "            model = GradientBoostingClassifier(n_estimators=n_est, learning_rate=lr, max_depth=depth)\n",
        "            model.fit(X_train, y_train)\n",
        "            val_score = model.score(X_val, y_val)\n",
        "\n",
        "            if val_score > best_gbm_score:\n",
        "                best_gbm_score = val_score\n",
        "                best_gbm = model\n",
        "\n",
        "            print(f\"n_est: {n_est}, lr: {lr}, depth: {depth}, Val Acc: {val_score:.4f}\")\n",
        "\n",
        "gbm_metrics = evaluate_model(best_gbm, X_test, y_test, \"Gradient Boosting Machine (Tuned)\")\n",
        "joblib.dump(best_gbm, '/content/drive/MyDrive/Colab Notebooks/gbm_model_tuned.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni5MVdyzicSg",
        "outputId": "08463b10-de9a-4961-d568-601d2d078974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning Gradient Boosting Machine...\n",
            "n_est: 25, lr: 0.1, depth: 2, Val Acc: 0.8184\n",
            "n_est: 25, lr: 0.1, depth: 3, Val Acc: 0.8397\n",
            "n_est: 25, lr: 0.1, depth: 4, Val Acc: 0.8500\n",
            "n_est: 25, lr: 0.2, depth: 2, Val Acc: 0.8400\n",
            "n_est: 25, lr: 0.2, depth: 3, Val Acc: 0.8535\n",
            "n_est: 25, lr: 0.2, depth: 4, Val Acc: 0.8665\n",
            "n_est: 25, lr: 0.3, depth: 2, Val Acc: 0.8473\n",
            "n_est: 25, lr: 0.3, depth: 3, Val Acc: 0.8631\n",
            "n_est: 25, lr: 0.3, depth: 4, Val Acc: 0.8824\n",
            "n_est: 50, lr: 0.1, depth: 2, Val Acc: 0.8342\n",
            "n_est: 50, lr: 0.1, depth: 3, Val Acc: 0.8546\n",
            "n_est: 50, lr: 0.1, depth: 4, Val Acc: 0.8636\n",
            "n_est: 50, lr: 0.2, depth: 2, Val Acc: 0.8581\n",
            "n_est: 50, lr: 0.2, depth: 3, Val Acc: 0.8742\n",
            "n_est: 50, lr: 0.2, depth: 4, Val Acc: 0.8886\n",
            "n_est: 50, lr: 0.3, depth: 2, Val Acc: 0.8643\n",
            "n_est: 50, lr: 0.3, depth: 3, Val Acc: 0.8873\n",
            "n_est: 50, lr: 0.3, depth: 4, Val Acc: 0.9037\n",
            "n_est: 75, lr: 0.1, depth: 2, Val Acc: 0.8504\n",
            "n_est: 75, lr: 0.1, depth: 3, Val Acc: 0.8659\n",
            "n_est: 75, lr: 0.1, depth: 4, Val Acc: 0.8801\n",
            "n_est: 75, lr: 0.2, depth: 2, Val Acc: 0.8614\n",
            "n_est: 75, lr: 0.2, depth: 3, Val Acc: 0.8835\n",
            "n_est: 75, lr: 0.2, depth: 4, Val Acc: 0.9022\n",
            "n_est: 75, lr: 0.3, depth: 2, Val Acc: 0.8743\n",
            "n_est: 75, lr: 0.3, depth: 3, Val Acc: 0.8959\n",
            "n_est: 75, lr: 0.3, depth: 4, Val Acc: 0.9141\n",
            "Gradient Boosting Machine (Tuned) Metrics:\n",
            "Accuracy: 0.9146\n",
            "Precision: 0.9151\n",
            "Recall: 0.8664\n",
            "F1 Score: 0.8901\n",
            "Average Inference Time: 0.000001 seconds\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/gbm_model_tuned.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Random Forest\n",
        "print(\"Tuning Random Forest...\")\n",
        "rf_params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 20, 40],\n",
        "    'min_samples_split': [2, 5, 7]\n",
        "}\n",
        "\n",
        "best_rf = None\n",
        "best_rf_score = 0\n",
        "\n",
        "for n_est in rf_params['n_estimators']:\n",
        "    for depth in rf_params['max_depth']:\n",
        "        for min_split in rf_params['min_samples_split']:\n",
        "            model = RandomForestClassifier(n_estimators=n_est, max_depth=depth,\n",
        "                                         min_samples_split=min_split, n_jobs=-1)\n",
        "            model.fit(X_train, y_train)\n",
        "            val_score = model.score(X_val, y_val)\n",
        "\n",
        "            if val_score > best_rf_score:\n",
        "                best_rf_score = val_score\n",
        "                best_rf = model\n",
        "\n",
        "            print(f\"n_est: {n_est}, depth: {depth}, min_split: {min_split}, Val Acc: {val_score:.4f}\")\n",
        "\n",
        "rf_metrics = evaluate_model(best_rf, X_test, y_test, \"Random Forest (Tuned)\")\n",
        "joblib.dump(best_rf, '/content/drive/MyDrive/Colab Notebooks/random_forest_model_tuned.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhKypuOGihTg",
        "outputId": "c3b6b0a1-d38e-44b5-91f4-3960a9c49adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning Random Forest...\n",
            "n_est: 50, depth: None, min_split: 2, Val Acc: 0.9804\n",
            "n_est: 50, depth: None, min_split: 5, Val Acc: 0.9809\n",
            "n_est: 50, depth: None, min_split: 7, Val Acc: 0.9806\n",
            "n_est: 50, depth: 20, min_split: 2, Val Acc: 0.9706\n",
            "n_est: 50, depth: 20, min_split: 5, Val Acc: 0.9698\n",
            "n_est: 50, depth: 20, min_split: 7, Val Acc: 0.9696\n",
            "n_est: 50, depth: 40, min_split: 2, Val Acc: 0.9807\n",
            "n_est: 50, depth: 40, min_split: 5, Val Acc: 0.9805\n",
            "n_est: 50, depth: 40, min_split: 7, Val Acc: 0.9806\n",
            "n_est: 100, depth: None, min_split: 2, Val Acc: 0.9807\n",
            "n_est: 100, depth: None, min_split: 5, Val Acc: 0.9808\n",
            "n_est: 100, depth: None, min_split: 7, Val Acc: 0.9808\n",
            "n_est: 100, depth: 20, min_split: 2, Val Acc: 0.9702\n",
            "n_est: 100, depth: 20, min_split: 5, Val Acc: 0.9712\n",
            "n_est: 100, depth: 20, min_split: 7, Val Acc: 0.9704\n",
            "n_est: 100, depth: 40, min_split: 2, Val Acc: 0.9810\n",
            "n_est: 100, depth: 40, min_split: 5, Val Acc: 0.9810\n",
            "n_est: 100, depth: 40, min_split: 7, Val Acc: 0.9809\n",
            "n_est: 200, depth: None, min_split: 2, Val Acc: 0.9808\n",
            "n_est: 200, depth: None, min_split: 5, Val Acc: 0.9812\n",
            "n_est: 200, depth: None, min_split: 7, Val Acc: 0.9806\n",
            "n_est: 200, depth: 20, min_split: 2, Val Acc: 0.9717\n",
            "n_est: 200, depth: 20, min_split: 5, Val Acc: 0.9708\n",
            "n_est: 200, depth: 20, min_split: 7, Val Acc: 0.9702\n",
            "n_est: 200, depth: 40, min_split: 2, Val Acc: 0.9809\n",
            "n_est: 200, depth: 40, min_split: 5, Val Acc: 0.9811\n",
            "n_est: 200, depth: 40, min_split: 7, Val Acc: 0.9811\n",
            "Random Forest (Tuned) Metrics:\n",
            "Accuracy: 0.9818\n",
            "Precision: 0.9876\n",
            "Recall: 0.9665\n",
            "F1 Score: 0.9770\n",
            "Average Inference Time: 0.000040 seconds\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/random_forest_model_tuned.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Neural Network (3 Hidden Layers)\n",
        "print(\"Tuning TensorFlow Neural Network...\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define hyperparameter search space\n",
        "learning_rates = [0.001, 0.0005, 0.0001]\n",
        "dropout_rates = [0.2, 0.3, 0.4]\n",
        "hidden_units = [128, 192, 256]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "best_model = None\n",
        "\n",
        "print(\"Starting hyperparameter tuning...\\n\")\n",
        "\n",
        "# Simple grid search over 3 hyperparameters\n",
        "for lr in learning_rates:\n",
        "    for dropout in dropout_rates:\n",
        "        for units in hidden_units:\n",
        "\n",
        "            print(f\"Testing: lr={lr}, dropout={dropout}, units={units}\")\n",
        "\n",
        "            # Build model with current hyperparameters\n",
        "            model = Sequential([\n",
        "                Dense(units, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "                Dropout(dropout),\n",
        "\n",
        "                Dense(int(units*0.5), activation='relu'),\n",
        "                Dropout(dropout),\n",
        "\n",
        "                Dense(int(units*0.25), activation='relu'),\n",
        "                Dropout(dropout),\n",
        "\n",
        "                Dense(1, activation='sigmoid')\n",
        "            ])\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=Adam(learning_rate=lr),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy']\n",
        "            )\n",
        "\n",
        "            history = model.fit(\n",
        "                X_train,\n",
        "                y_train,\n",
        "                epochs=10,\n",
        "                batch_size=128,\n",
        "                validation_split=0.2,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            # Evaluate on validation set\n",
        "            val_accuracy = history.history['val_accuracy'][-1]\n",
        "            print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "            # Save if best model\n",
        "            if val_accuracy > best_accuracy:\n",
        "                best_accuracy = val_accuracy\n",
        "                best_params = {\n",
        "                    'learning_rate': lr,\n",
        "                    'dropout_rate': dropout,\n",
        "                    'hidden_units': units\n",
        "                }\n",
        "                best_model = model\n",
        "                print(\"New best model found!\\n\")\n",
        "\n",
        "# Train best model on full training data\n",
        "print(\"\\nTraining best model on full dataset...\")\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "history = best_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f\"\\nSelected configuration:\")\n",
        "print(f\"- Learning rate: {best_params['learning_rate']}\")\n",
        "print(f\"- Dropout rate: {best_params['dropout_rate']}\")\n",
        "print(f\"- Hidden units: {best_params['hidden_units']}\")\n",
        "\n",
        "# Evaluate best model\n",
        "tf_metrics = evaluate_tf_model(best_model, X_test, y_test, \"TensorFlow Neural Network (Tuned)\")\n",
        "\n",
        "# Save best model\n",
        "best_model.save('/content/drive/MyDrive/Colab Notebooks/tf_neural_network_model_tuned.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IGgJKQ9PhreN",
        "outputId": "bc02598c-4bb8-4a4b-f552-1f8d446170c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning TensorFlow Neural Network...\n",
            "Starting hyperparameter tuning...\n",
            "\n",
            "Testing: lr=0.001, dropout=0.2, units=128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4ms/step - accuracy: 0.8198 - loss: 0.4047 - val_accuracy: 0.8757 - val_loss: 0.3059\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 0.3178 - val_accuracy: 0.8946 - val_loss: 0.2673\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.2923 - val_accuracy: 0.9034 - val_loss: 0.2497\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8924 - loss: 0.2774 - val_accuracy: 0.9086 - val_loss: 0.2396\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.2679 - val_accuracy: 0.9131 - val_loss: 0.2289\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9001 - loss: 0.2619 - val_accuracy: 0.9174 - val_loss: 0.2227\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.2558 - val_accuracy: 0.9196 - val_loss: 0.2181\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.2519 - val_accuracy: 0.9214 - val_loss: 0.2145\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.2477 - val_accuracy: 0.9234 - val_loss: 0.2097\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 0.2446 - val_accuracy: 0.9246 - val_loss: 0.2065\n",
            "Validation accuracy: 0.9246\n",
            "New best model found!\n",
            "\n",
            "Testing: lr=0.001, dropout=0.2, units=192\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8300 - loss: 0.3866 - val_accuracy: 0.8860 - val_loss: 0.2847\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8815 - loss: 0.2980 - val_accuracy: 0.9074 - val_loss: 0.2468\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8952 - loss: 0.2709 - val_accuracy: 0.9158 - val_loss: 0.2297\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9039 - loss: 0.2541 - val_accuracy: 0.9213 - val_loss: 0.2157\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9087 - loss: 0.2435 - val_accuracy: 0.9256 - val_loss: 0.2050\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.2383 - val_accuracy: 0.9272 - val_loss: 0.2010\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9140 - loss: 0.2315 - val_accuracy: 0.9305 - val_loss: 0.1958\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9168 - loss: 0.2272 - val_accuracy: 0.9318 - val_loss: 0.1917\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9172 - loss: 0.2249 - val_accuracy: 0.9322 - val_loss: 0.1880\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9189 - loss: 0.2215 - val_accuracy: 0.9352 - val_loss: 0.1839\n",
            "Validation accuracy: 0.9352\n",
            "New best model found!\n",
            "\n",
            "Testing: lr=0.001, dropout=0.2, units=256\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 0.3760 - val_accuracy: 0.8951 - val_loss: 0.2676\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.2809 - val_accuracy: 0.9134 - val_loss: 0.2345\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.2496 - val_accuracy: 0.9230 - val_loss: 0.2093\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9117 - loss: 0.2344 - val_accuracy: 0.9278 - val_loss: 0.2007\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9159 - loss: 0.2267 - val_accuracy: 0.9313 - val_loss: 0.1913\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9210 - loss: 0.2158 - val_accuracy: 0.9356 - val_loss: 0.1844\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9226 - loss: 0.2133 - val_accuracy: 0.9363 - val_loss: 0.1791\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.2071 - val_accuracy: 0.9383 - val_loss: 0.1760\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.9269 - loss: 0.2039 - val_accuracy: 0.9389 - val_loss: 0.1742\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9278 - loss: 0.2006 - val_accuracy: 0.9390 - val_loss: 0.1722\n",
            "Validation accuracy: 0.9390\n",
            "New best model found!\n",
            "\n",
            "Testing: lr=0.001, dropout=0.3, units=128\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8077 - loss: 0.4246 - val_accuracy: 0.8738 - val_loss: 0.3125\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8635 - loss: 0.3364 - val_accuracy: 0.8909 - val_loss: 0.2796\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8771 - loss: 0.3096 - val_accuracy: 0.9000 - val_loss: 0.2605\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.2956 - val_accuracy: 0.9048 - val_loss: 0.2510\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.8895 - loss: 0.2861 - val_accuracy: 0.9080 - val_loss: 0.2412\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.2791 - val_accuracy: 0.9111 - val_loss: 0.2386\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.2759 - val_accuracy: 0.9147 - val_loss: 0.2316\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8952 - loss: 0.2731 - val_accuracy: 0.9151 - val_loss: 0.2297\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8969 - loss: 0.2705 - val_accuracy: 0.9180 - val_loss: 0.2243\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.8978 - loss: 0.2693 - val_accuracy: 0.9178 - val_loss: 0.2259\n",
            "Validation accuracy: 0.9178\n",
            "Testing: lr=0.001, dropout=0.3, units=192\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8171 - loss: 0.4071 - val_accuracy: 0.8831 - val_loss: 0.2986\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8747 - loss: 0.3160 - val_accuracy: 0.8968 - val_loss: 0.2631\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8867 - loss: 0.2898 - val_accuracy: 0.9070 - val_loss: 0.2448\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8941 - loss: 0.2756 - val_accuracy: 0.9125 - val_loss: 0.2323\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.2653 - val_accuracy: 0.9174 - val_loss: 0.2226\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9025 - loss: 0.2581 - val_accuracy: 0.9190 - val_loss: 0.2166\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.2538 - val_accuracy: 0.9217 - val_loss: 0.2132\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9054 - loss: 0.2507 - val_accuracy: 0.9237 - val_loss: 0.2081\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.2472 - val_accuracy: 0.9251 - val_loss: 0.2075\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 0.2431 - val_accuracy: 0.9282 - val_loss: 0.2037\n",
            "Validation accuracy: 0.9282\n",
            "Testing: lr=0.001, dropout=0.3, units=256\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.3934 - val_accuracy: 0.8865 - val_loss: 0.2867\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8783 - loss: 0.3054 - val_accuracy: 0.9055 - val_loss: 0.2493\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8937 - loss: 0.2757 - val_accuracy: 0.9154 - val_loss: 0.2302\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9021 - loss: 0.2592 - val_accuracy: 0.9188 - val_loss: 0.2209\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9057 - loss: 0.2509 - val_accuracy: 0.9212 - val_loss: 0.2146\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9086 - loss: 0.2440 - val_accuracy: 0.9256 - val_loss: 0.2059\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9118 - loss: 0.2374 - val_accuracy: 0.9256 - val_loss: 0.2017\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9132 - loss: 0.2347 - val_accuracy: 0.9303 - val_loss: 0.1945\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.2316 - val_accuracy: 0.9316 - val_loss: 0.1934\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9151 - loss: 0.2294 - val_accuracy: 0.9322 - val_loss: 0.1901\n",
            "Validation accuracy: 0.9322\n",
            "Testing: lr=0.001, dropout=0.4, units=128\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 0.4388 - val_accuracy: 0.8647 - val_loss: 0.3327\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8536 - loss: 0.3539 - val_accuracy: 0.8813 - val_loss: 0.3002\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8652 - loss: 0.3356 - val_accuracy: 0.8906 - val_loss: 0.2865\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.3236 - val_accuracy: 0.8947 - val_loss: 0.2756\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8744 - loss: 0.3164 - val_accuracy: 0.8987 - val_loss: 0.2647\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8788 - loss: 0.3096 - val_accuracy: 0.9016 - val_loss: 0.2643\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8801 - loss: 0.3061 - val_accuracy: 0.9046 - val_loss: 0.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.3030 - val_accuracy: 0.9057 - val_loss: 0.2552\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.2993 - val_accuracy: 0.9082 - val_loss: 0.2479\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8855 - loss: 0.2966 - val_accuracy: 0.9093 - val_loss: 0.2482\n",
            "Validation accuracy: 0.9093\n",
            "Testing: lr=0.001, dropout=0.4, units=192\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.4179 - val_accuracy: 0.8724 - val_loss: 0.3124\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8628 - loss: 0.3355 - val_accuracy: 0.8886 - val_loss: 0.2849\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.8730 - loss: 0.3157 - val_accuracy: 0.8975 - val_loss: 0.2655\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8822 - loss: 0.2989 - val_accuracy: 0.9002 - val_loss: 0.2586\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.8843 - loss: 0.2924 - val_accuracy: 0.9079 - val_loss: 0.2462\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8902 - loss: 0.2842 - val_accuracy: 0.9091 - val_loss: 0.2405\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8917 - loss: 0.2788 - val_accuracy: 0.9120 - val_loss: 0.2325\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.8943 - loss: 0.2761 - val_accuracy: 0.9152 - val_loss: 0.2332\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.2716 - val_accuracy: 0.9173 - val_loss: 0.2282\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8969 - loss: 0.2693 - val_accuracy: 0.9173 - val_loss: 0.2241\n",
            "Validation accuracy: 0.9173\n",
            "Testing: lr=0.001, dropout=0.4, units=256\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.8165 - loss: 0.4102 - val_accuracy: 0.8792 - val_loss: 0.3056\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8705 - loss: 0.3210 - val_accuracy: 0.8983 - val_loss: 0.2679\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8844 - loss: 0.2952 - val_accuracy: 0.9059 - val_loss: 0.2489\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8903 - loss: 0.2839 - val_accuracy: 0.9122 - val_loss: 0.2380\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8948 - loss: 0.2746 - val_accuracy: 0.9154 - val_loss: 0.2278\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8980 - loss: 0.2693 - val_accuracy: 0.9175 - val_loss: 0.2231\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9003 - loss: 0.2619 - val_accuracy: 0.9195 - val_loss: 0.2195\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9016 - loss: 0.2594 - val_accuracy: 0.9216 - val_loss: 0.2149\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9042 - loss: 0.2542 - val_accuracy: 0.9228 - val_loss: 0.2105\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.9056 - loss: 0.2513 - val_accuracy: 0.9237 - val_loss: 0.2087\n",
            "Validation accuracy: 0.9237\n",
            "Testing: lr=0.0005, dropout=0.2, units=128\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.4280 - val_accuracy: 0.8700 - val_loss: 0.3201\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8616 - loss: 0.3380 - val_accuracy: 0.8858 - val_loss: 0.2909\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8744 - loss: 0.3138 - val_accuracy: 0.8964 - val_loss: 0.2678\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.8842 - loss: 0.2964 - val_accuracy: 0.9051 - val_loss: 0.2557\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8911 - loss: 0.2828 - val_accuracy: 0.9095 - val_loss: 0.2456\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.8949 - loss: 0.2749 - val_accuracy: 0.9129 - val_loss: 0.2374\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8988 - loss: 0.2674 - val_accuracy: 0.9157 - val_loss: 0.2288\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9003 - loss: 0.2622 - val_accuracy: 0.9168 - val_loss: 0.2242\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.2563 - val_accuracy: 0.9194 - val_loss: 0.2202\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9051 - loss: 0.2531 - val_accuracy: 0.9206 - val_loss: 0.2156\n",
            "Validation accuracy: 0.9206\n",
            "Testing: lr=0.0005, dropout=0.2, units=192\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 0.4068 - val_accuracy: 0.8758 - val_loss: 0.3034\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8719 - loss: 0.3145 - val_accuracy: 0.8976 - val_loss: 0.2678\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8871 - loss: 0.2858 - val_accuracy: 0.9071 - val_loss: 0.2437\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8967 - loss: 0.2681 - val_accuracy: 0.9153 - val_loss: 0.2287\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9024 - loss: 0.2555 - val_accuracy: 0.9183 - val_loss: 0.2171\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9082 - loss: 0.2445 - val_accuracy: 0.9228 - val_loss: 0.2098\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9101 - loss: 0.2391 - val_accuracy: 0.9252 - val_loss: 0.2044\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9130 - loss: 0.2344 - val_accuracy: 0.9277 - val_loss: 0.1990\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.2285 - val_accuracy: 0.9286 - val_loss: 0.1937\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9166 - loss: 0.2257 - val_accuracy: 0.9325 - val_loss: 0.1897\n",
            "Validation accuracy: 0.9325\n",
            "Testing: lr=0.0005, dropout=0.2, units=256\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8207 - loss: 0.3989 - val_accuracy: 0.8831 - val_loss: 0.2957\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8747 - loss: 0.3077 - val_accuracy: 0.9024 - val_loss: 0.2552\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8927 - loss: 0.2761 - val_accuracy: 0.9148 - val_loss: 0.2310\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9033 - loss: 0.2535 - val_accuracy: 0.9203 - val_loss: 0.2179\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9098 - loss: 0.2419 - val_accuracy: 0.9264 - val_loss: 0.2044\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.2312 - val_accuracy: 0.9301 - val_loss: 0.1959\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9182 - loss: 0.2225 - val_accuracy: 0.9317 - val_loss: 0.1892\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.2163 - val_accuracy: 0.9342 - val_loss: 0.1839\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.9222 - loss: 0.2131 - val_accuracy: 0.9364 - val_loss: 0.1809\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.2072 - val_accuracy: 0.9387 - val_loss: 0.1757\n",
            "Validation accuracy: 0.9387\n",
            "Testing: lr=0.0005, dropout=0.3, units=128\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4488 - val_accuracy: 0.8590 - val_loss: 0.3409\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8493 - loss: 0.3593 - val_accuracy: 0.8778 - val_loss: 0.3092\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.3331 - val_accuracy: 0.8888 - val_loss: 0.2882\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.8727 - loss: 0.3187 - val_accuracy: 0.8947 - val_loss: 0.2735\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.3044 - val_accuracy: 0.9010 - val_loss: 0.2623\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8838 - loss: 0.2965 - val_accuracy: 0.9049 - val_loss: 0.2525\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8872 - loss: 0.2902 - val_accuracy: 0.9092 - val_loss: 0.2451\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8902 - loss: 0.2847 - val_accuracy: 0.9119 - val_loss: 0.2405\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.2787 - val_accuracy: 0.9141 - val_loss: 0.2365\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8935 - loss: 0.2780 - val_accuracy: 0.9153 - val_loss: 0.2336\n",
            "Validation accuracy: 0.9153\n",
            "Testing: lr=0.0005, dropout=0.3, units=192\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.4260 - val_accuracy: 0.8669 - val_loss: 0.3220\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8588 - loss: 0.3403 - val_accuracy: 0.8886 - val_loss: 0.2838\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.3115 - val_accuracy: 0.8978 - val_loss: 0.2636\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8854 - loss: 0.2921 - val_accuracy: 0.9056 - val_loss: 0.2496\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.8906 - loss: 0.2813 - val_accuracy: 0.9092 - val_loss: 0.2399\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8952 - loss: 0.2722 - val_accuracy: 0.9133 - val_loss: 0.2320\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8989 - loss: 0.2642 - val_accuracy: 0.9179 - val_loss: 0.2228\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9010 - loss: 0.2596 - val_accuracy: 0.9200 - val_loss: 0.2174\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9027 - loss: 0.2561 - val_accuracy: 0.9214 - val_loss: 0.2153\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9047 - loss: 0.2532 - val_accuracy: 0.9236 - val_loss: 0.2112\n",
            "Validation accuracy: 0.9236\n",
            "Testing: lr=0.0005, dropout=0.3, units=256\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.8131 - loss: 0.4118 - val_accuracy: 0.8730 - val_loss: 0.3106\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 7ms/step - accuracy: 0.8666 - loss: 0.3245 - val_accuracy: 0.8945 - val_loss: 0.2719\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.8822 - loss: 0.2955 - val_accuracy: 0.9052 - val_loss: 0.2477\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - accuracy: 0.8931 - loss: 0.2759 - val_accuracy: 0.9123 - val_loss: 0.2334\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 8ms/step - accuracy: 0.8999 - loss: 0.2622 - val_accuracy: 0.9172 - val_loss: 0.2235\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9041 - loss: 0.2529 - val_accuracy: 0.9221 - val_loss: 0.2140\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - accuracy: 0.9073 - loss: 0.2457 - val_accuracy: 0.9241 - val_loss: 0.2075\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9094 - loss: 0.2404 - val_accuracy: 0.9268 - val_loss: 0.2027\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.9123 - loss: 0.2363 - val_accuracy: 0.9279 - val_loss: 0.1983\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2311 - val_accuracy: 0.9288 - val_loss: 0.1942\n",
            "Validation accuracy: 0.9288\n",
            "Testing: lr=0.0005, dropout=0.4, units=128\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.7772 - loss: 0.4704 - val_accuracy: 0.8501 - val_loss: 0.3586\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8411 - loss: 0.3779 - val_accuracy: 0.8638 - val_loss: 0.3265\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8537 - loss: 0.3535 - val_accuracy: 0.8773 - val_loss: 0.3054\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8620 - loss: 0.3393 - val_accuracy: 0.8851 - val_loss: 0.2900\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8681 - loss: 0.3276 - val_accuracy: 0.8935 - val_loss: 0.2804\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8721 - loss: 0.3208 - val_accuracy: 0.8957 - val_loss: 0.2742\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.3158 - val_accuracy: 0.8981 - val_loss: 0.2689\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.3090 - val_accuracy: 0.9024 - val_loss: 0.2658\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8794 - loss: 0.3066 - val_accuracy: 0.9031 - val_loss: 0.2591\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.3026 - val_accuracy: 0.9049 - val_loss: 0.2575\n",
            "Validation accuracy: 0.9049\n",
            "Testing: lr=0.0005, dropout=0.4, units=192\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.7930 - loss: 0.4441 - val_accuracy: 0.8632 - val_loss: 0.3352\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8502 - loss: 0.3580 - val_accuracy: 0.8790 - val_loss: 0.3033\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8650 - loss: 0.3314 - val_accuracy: 0.8894 - val_loss: 0.2848\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8736 - loss: 0.3135 - val_accuracy: 0.9008 - val_loss: 0.2682\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8806 - loss: 0.3017 - val_accuracy: 0.9056 - val_loss: 0.2547\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8847 - loss: 0.2933 - val_accuracy: 0.9074 - val_loss: 0.2473\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.8881 - loss: 0.2868 - val_accuracy: 0.9117 - val_loss: 0.2404\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8908 - loss: 0.2821 - val_accuracy: 0.9135 - val_loss: 0.2353\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.8944 - loss: 0.2749 - val_accuracy: 0.9157 - val_loss: 0.2317\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.8948 - loss: 0.2734 - val_accuracy: 0.9172 - val_loss: 0.2291\n",
            "Validation accuracy: 0.9172\n",
            "Testing: lr=0.0005, dropout=0.4, units=256\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7990 - loss: 0.4326 - val_accuracy: 0.8631 - val_loss: 0.3281\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8584 - loss: 0.3422 - val_accuracy: 0.8862 - val_loss: 0.2927\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8737 - loss: 0.3136 - val_accuracy: 0.8966 - val_loss: 0.2704\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8825 - loss: 0.2968 - val_accuracy: 0.9059 - val_loss: 0.2518\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8896 - loss: 0.2847 - val_accuracy: 0.9110 - val_loss: 0.2414\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8937 - loss: 0.2762 - val_accuracy: 0.9145 - val_loss: 0.2303\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.8968 - loss: 0.2699 - val_accuracy: 0.9177 - val_loss: 0.2233\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9006 - loss: 0.2627 - val_accuracy: 0.9204 - val_loss: 0.2186\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9027 - loss: 0.2593 - val_accuracy: 0.9216 - val_loss: 0.2161\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9045 - loss: 0.2550 - val_accuracy: 0.9255 - val_loss: 0.2115\n",
            "Validation accuracy: 0.9255\n",
            "Testing: lr=0.0001, dropout=0.2, units=128\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.4915 - val_accuracy: 0.8338 - val_loss: 0.3864\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.8260 - loss: 0.4002 - val_accuracy: 0.8459 - val_loss: 0.3612\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8399 - loss: 0.3759 - val_accuracy: 0.8543 - val_loss: 0.3430\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8472 - loss: 0.3618 - val_accuracy: 0.8624 - val_loss: 0.3293\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8522 - loss: 0.3525 - val_accuracy: 0.8707 - val_loss: 0.3189\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 0.3424 - val_accuracy: 0.8755 - val_loss: 0.3098\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8629 - loss: 0.3332 - val_accuracy: 0.8808 - val_loss: 0.3025\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.8666 - loss: 0.3249 - val_accuracy: 0.8840 - val_loss: 0.2949\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8704 - loss: 0.3197 - val_accuracy: 0.8870 - val_loss: 0.2890\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8730 - loss: 0.3160 - val_accuracy: 0.8896 - val_loss: 0.2833\n",
            "Validation accuracy: 0.8896\n",
            "Testing: lr=0.0001, dropout=0.2, units=192\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.7757 - loss: 0.4666 - val_accuracy: 0.8405 - val_loss: 0.3689\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8356 - loss: 0.3805 - val_accuracy: 0.8589 - val_loss: 0.3406\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.3569 - val_accuracy: 0.8687 - val_loss: 0.3228\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8573 - loss: 0.3427 - val_accuracy: 0.8747 - val_loss: 0.3094\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8647 - loss: 0.3294 - val_accuracy: 0.8808 - val_loss: 0.2980\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.3191 - val_accuracy: 0.8853 - val_loss: 0.2870\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.8758 - loss: 0.3093 - val_accuracy: 0.8913 - val_loss: 0.2789\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8791 - loss: 0.3034 - val_accuracy: 0.8940 - val_loss: 0.2719\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8825 - loss: 0.2975 - val_accuracy: 0.8985 - val_loss: 0.2664\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8850 - loss: 0.2913 - val_accuracy: 0.8990 - val_loss: 0.2600\n",
            "Validation accuracy: 0.8990\n",
            "Testing: lr=0.0001, dropout=0.2, units=256\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.7869 - loss: 0.4536 - val_accuracy: 0.8468 - val_loss: 0.3579\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8433 - loss: 0.3669 - val_accuracy: 0.8611 - val_loss: 0.3300\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8554 - loss: 0.3437 - val_accuracy: 0.8748 - val_loss: 0.3106\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8640 - loss: 0.3292 - val_accuracy: 0.8830 - val_loss: 0.2942\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8727 - loss: 0.3137 - val_accuracy: 0.8905 - val_loss: 0.2827\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8786 - loss: 0.3041 - val_accuracy: 0.8947 - val_loss: 0.2706\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8829 - loss: 0.2952 - val_accuracy: 0.8999 - val_loss: 0.2625\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8864 - loss: 0.2881 - val_accuracy: 0.9042 - val_loss: 0.2542\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8913 - loss: 0.2788 - val_accuracy: 0.9087 - val_loss: 0.2465\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8937 - loss: 0.2740 - val_accuracy: 0.9109 - val_loss: 0.2417\n",
            "Validation accuracy: 0.9109\n",
            "Testing: lr=0.0001, dropout=0.3, units=128\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7383 - loss: 0.5157 - val_accuracy: 0.8273 - val_loss: 0.3947\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8177 - loss: 0.4146 - val_accuracy: 0.8362 - val_loss: 0.3743\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8287 - loss: 0.3958 - val_accuracy: 0.8465 - val_loss: 0.3578\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.3807 - val_accuracy: 0.8564 - val_loss: 0.3436\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8440 - loss: 0.3702 - val_accuracy: 0.8625 - val_loss: 0.3335\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8489 - loss: 0.3616 - val_accuracy: 0.8692 - val_loss: 0.3226\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8540 - loss: 0.3527 - val_accuracy: 0.8742 - val_loss: 0.3148\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.3458 - val_accuracy: 0.8775 - val_loss: 0.3092\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8620 - loss: 0.3383 - val_accuracy: 0.8801 - val_loss: 0.3032\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8644 - loss: 0.3339 - val_accuracy: 0.8838 - val_loss: 0.2972\n",
            "Validation accuracy: 0.8838\n",
            "Testing: lr=0.0001, dropout=0.3, units=192\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.7558 - loss: 0.4900 - val_accuracy: 0.8367 - val_loss: 0.3819\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 0.4003 - val_accuracy: 0.8454 - val_loss: 0.3575\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 0.3778 - val_accuracy: 0.8580 - val_loss: 0.3399\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.8467 - loss: 0.3617 - val_accuracy: 0.8622 - val_loss: 0.3269\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8523 - loss: 0.3496 - val_accuracy: 0.8682 - val_loss: 0.3166\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 0.3402 - val_accuracy: 0.8710 - val_loss: 0.3081\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.8618 - loss: 0.3319 - val_accuracy: 0.8795 - val_loss: 0.2992\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8666 - loss: 0.3252 - val_accuracy: 0.8853 - val_loss: 0.2927\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8704 - loss: 0.3195 - val_accuracy: 0.8871 - val_loss: 0.2843\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8733 - loss: 0.3135 - val_accuracy: 0.8909 - val_loss: 0.2775\n",
            "Validation accuracy: 0.8909\n",
            "Testing: lr=0.0001, dropout=0.3, units=256\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7777 - loss: 0.4642 - val_accuracy: 0.8417 - val_loss: 0.3670\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8363 - loss: 0.3814 - val_accuracy: 0.8534 - val_loss: 0.3404\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8480 - loss: 0.3598 - val_accuracy: 0.8661 - val_loss: 0.3240\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.3460 - val_accuracy: 0.8717 - val_loss: 0.3096\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8612 - loss: 0.3352 - val_accuracy: 0.8796 - val_loss: 0.2998\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.3224 - val_accuracy: 0.8862 - val_loss: 0.2901\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8730 - loss: 0.3138 - val_accuracy: 0.8900 - val_loss: 0.2786\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8775 - loss: 0.3063 - val_accuracy: 0.8947 - val_loss: 0.2707\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8812 - loss: 0.2992 - val_accuracy: 0.8995 - val_loss: 0.2629\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8851 - loss: 0.2914 - val_accuracy: 0.9040 - val_loss: 0.2574\n",
            "Validation accuracy: 0.9040\n",
            "Testing: lr=0.0001, dropout=0.4, units=128\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.7174 - loss: 0.5423 - val_accuracy: 0.8201 - val_loss: 0.4037\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.4348 - val_accuracy: 0.8354 - val_loss: 0.3846\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8204 - loss: 0.4123 - val_accuracy: 0.8426 - val_loss: 0.3710\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8292 - loss: 0.3970 - val_accuracy: 0.8463 - val_loss: 0.3584\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8351 - loss: 0.3867 - val_accuracy: 0.8552 - val_loss: 0.3480\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.3770 - val_accuracy: 0.8620 - val_loss: 0.3406\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3698 - val_accuracy: 0.8631 - val_loss: 0.3334\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8477 - loss: 0.3652 - val_accuracy: 0.8667 - val_loss: 0.3279\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8504 - loss: 0.3590 - val_accuracy: 0.8704 - val_loss: 0.3232\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8538 - loss: 0.3537 - val_accuracy: 0.8725 - val_loss: 0.3179\n",
            "Validation accuracy: 0.8725\n",
            "Testing: lr=0.0001, dropout=0.4, units=192\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.7446 - loss: 0.5089 - val_accuracy: 0.8268 - val_loss: 0.3947\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.8169 - loss: 0.4135 - val_accuracy: 0.8395 - val_loss: 0.3721\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8296 - loss: 0.3931 - val_accuracy: 0.8527 - val_loss: 0.3571\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 0.3760 - val_accuracy: 0.8567 - val_loss: 0.3428\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8457 - loss: 0.3654 - val_accuracy: 0.8625 - val_loss: 0.3338\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8495 - loss: 0.3575 - val_accuracy: 0.8678 - val_loss: 0.3256\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.3508 - val_accuracy: 0.8748 - val_loss: 0.3181\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.3439 - val_accuracy: 0.8791 - val_loss: 0.3117\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8603 - loss: 0.3394 - val_accuracy: 0.8824 - val_loss: 0.3041\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8640 - loss: 0.3320 - val_accuracy: 0.8852 - val_loss: 0.3003\n",
            "Validation accuracy: 0.8852\n",
            "Testing: lr=0.0001, dropout=0.4, units=256\n",
            "Epoch 1/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7523 - loss: 0.4934 - val_accuracy: 0.8353 - val_loss: 0.3826\n",
            "Epoch 2/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.8246 - loss: 0.4018 - val_accuracy: 0.8487 - val_loss: 0.3582\n",
            "Epoch 3/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - accuracy: 0.8380 - loss: 0.3791 - val_accuracy: 0.8581 - val_loss: 0.3419\n",
            "Epoch 4/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - accuracy: 0.8468 - loss: 0.3641 - val_accuracy: 0.8650 - val_loss: 0.3295\n",
            "Epoch 5/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.8541 - loss: 0.3509 - val_accuracy: 0.8727 - val_loss: 0.3186\n",
            "Epoch 6/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8580 - loss: 0.3435 - val_accuracy: 0.8750 - val_loss: 0.3080\n",
            "Epoch 7/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8622 - loss: 0.3357 - val_accuracy: 0.8806 - val_loss: 0.3004\n",
            "Epoch 8/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8661 - loss: 0.3280 - val_accuracy: 0.8846 - val_loss: 0.2928\n",
            "Epoch 9/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8704 - loss: 0.3211 - val_accuracy: 0.8883 - val_loss: 0.2867\n",
            "Epoch 10/10\n",
            "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8738 - loss: 0.3147 - val_accuracy: 0.8919 - val_loss: 0.2809\n",
            "Validation accuracy: 0.8919\n",
            "\n",
            "Training best model on full dataset...\n",
            "Best parameters: {'learning_rate': 0.001, 'dropout_rate': 0.2, 'hidden_units': 256}\n",
            "Epoch 1/10\n",
            "\u001b[1m4151/4151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9283 - loss: 0.1986\n",
            "Epoch 2/10\n",
            "\u001b[1m4151/4151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9293 - loss: 0.1967\n",
            "Epoch 3/10\n",
            "\u001b[1m4151/4151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9314 - loss: 0.1916\n",
            "Epoch 4/10\n",
            "\u001b[1m4151/4151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9324 - loss: 0.1910\n",
            "Epoch 5/10\n",
            "\u001b[1m4151/4151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9333 - loss: 0.1882\n",
            "Epoch 6/10\n",
            "\u001b[1m4151/4151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9333 - loss: 0.1869\n",
            "Epoch 7/10\n",
            "\u001b[1m4151/4151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9339 - loss: 0.1866\n",
            "Epoch 8/10\n",
            "\u001b[1m4151/4151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9353 - loss: 0.1838\n",
            "Epoch 9/10\n",
            "\u001b[1m4151/4151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.9355 - loss: 0.1816\n",
            "Epoch 10/10\n",
            "\u001b[1m4151/4151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9348 - loss: 0.1834\n",
            "\n",
            "Selected configuration:\n",
            "- Learning rate: 0.001\n",
            "- Dropout rate: 0.2\n",
            "- Hidden units: 256\n",
            "\u001b[1m5189/5189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TensorFlow Neural Network (Tuned) Metrics:\n",
            "Accuracy: 0.9464\n",
            "Precision: 0.9665\n",
            "Recall: 0.8969\n",
            "F1 Score: 0.9304\n",
            "Average Inference Time: 0.000058 seconds\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'val_accuracy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b13284db2919>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Model Training History'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Further tuning and evaluation of the Neural Network binary classifier:**"
      ],
      "metadata": {
        "id": "rDrgmywQv3gW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs\n",
        "!pip install keras_tuner\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import tensorflowjs as tfjs\n",
        "import pandas as pd\n",
        "\n",
        "# Load the training data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "X_train = train_data.drop('label', axis=1)\n",
        "y_train = train_data['label']\n",
        "\n",
        "# Load the test data\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv')\n",
        "X_test = test_data.drop('label', axis=1)\n",
        "y_test = test_data['label']\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define a model builder function for Keras Tuner\n",
        "def model_builder(hp):\n",
        "    model = Sequential()\n",
        "    # Input layer\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('units_input', min_value=128, max_value=512, step=64),\n",
        "        activation='relu',\n",
        "        input_shape=(X_train.shape[1],)\n",
        "    ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(hp.Float('dropout_input', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Hidden layer\n",
        "    for i in range(hp.Int('num_hidden_layers', 1, 3)):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'units_hidden_{i}', min_value=64, max_value=256, step=64),\n",
        "            activation='relu',\n",
        "            kernel_regularizer=l2(hp.Choice(f'l2_hidden_{i}', values=[0.001, 0.01, 0.1]))\n",
        "        ))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(hp.Float(f'dropout_hidden_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[0.001, 0.0005, 0.0001])),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Initialize Keras Tuner\n",
        "tuner = kt.Hyperband(\n",
        "    model_builder,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory='my_tuning',\n",
        "    project_name='binary_classification'\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Perform the search\n",
        "tuner.search(X_train, y_train, epochs=20, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Retrieve the best model\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the best model\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=128, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "\n",
        "# Convert and save the model to TensorFlow.js format\n",
        "tfjs.converters.save_keras_model(model, '/content/drive/MyDrive/Colab Notebooks/tuned_classifier')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "hawhuNwy_Fvz",
        "outputId": "ef72622e-7289-4ee0-cd95-31020622b1c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<p style=\"margin:0px;\">🌲 Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
              "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
              "        Decision Forests</a> using the same algorithms but with more features and faster\n",
              "    training!\n",
              "</p>\n",
              "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            Old code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import tensorflow_decision_forests as tfdf\n",
              "\n",
              "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
              "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
              "model.fit(tf_ds)\n",
              "</pre>\n",
              "    </div>\n",
              "    <div style=\"width: 5px;\"></div>\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            New code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import ydf\n",
              "\n",
              "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
              "</pre>\n",
              "    </div>\n",
              "</div>\n",
              "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
              "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
              "        guide</a>)</p>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "384               |384               |units_input\n",
            "0.1               |0.1               |dropout_input\n",
            "2                 |2                 |num_hidden_layers\n",
            "64                |64                |units_hidden_0\n",
            "0.01              |0.01              |l2_hidden_0\n",
            "0.1               |0.1               |dropout_hidden_0\n",
            "0.0001            |0.0001            |learning_rate\n",
            "3                 |3                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "2                 |2                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "Epoch 1/3\n",
            "\u001b[1m 5314/16604\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 1.3212 - precision: 0.7335 - recall: 0.7425"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-51a098adb756>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Perform the search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Retrieve the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Save the build config for model loading later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}